# -*- coding: utf-8 -*-
"""11-04

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IiPqomA4x-0Rb7ySZ4X4HUeilnBxzs0C
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd

df = pd.read_csv('/content/drive/MyDrive/local_rank_ffb_list.csv')
print(df)

print("Number of rows:", len(df))

import pandas as pd
from collections import defaultdict

df = pd.read_csv('/content/drive/MyDrive/local_rank_ffb_list.csv')

file_blocks = defaultdict(int)

for group, group_df in df.groupby(['rid', 'did']):
    rid, did = group
    file_blocks[f"{rid}{did}"] = len(group_df)

sorted_file_blocks = sorted(file_blocks.items(), key=lambda x: x[0])

output_data = []

for rid in range(1, 11):
    for did in range(1, 11):
        id = f"R{rid}D{did}"
        output_data.append([id, file_blocks[id]])

output_df = pd.DataFrame(output_data, columns=['id', 'file blocks'])

output_df.to_csv('file blocks.csv', index=False)

print(output_df)

total_file_blocks = sum(file_blocks.values())
print("sum of all file blockss :",total_file_blocks)

import pandas as pd

df = pd.read_csv('/content/drive/MyDrive/local_rank_ffb_list.csv',index_col=0)

df = df.dropna(subset=['rid', 'did', 'fid', 'bids'])
grouped = df.groupby(['rid', 'did'])
output_df = pd.DataFrame()

for name, group in grouped:
    rid, did = name
    total_lines = len(group)
    threshold = int(total_lines * 0.6)
    top_60_percent = group.iloc[:threshold]
    output_df = pd.concat([output_df, top_60_percent], ignore_index=True)

output_df.to_csv('filtered data(60%).csv', index=False)

print(output_df)

print(f"Total number of lines: {len(df)}")
print(f"Number of lines in the output (top 60%): {len(output_df)}")

import pandas as pd
from collections import defaultdict

df = pd.read_csv('/content/filtered data(60%).csv')

file_blocks = defaultdict(int)

for group, group_df in df.groupby(['rid', 'did']):
    rid, did = group
    file_blocks[f"{rid}{did}"] = len(group_df)

sorted_file_blocks = sorted(file_blocks.items(), key=lambda x: x[0])

output_data = []

for rid in range(1, 11):
    for did in range(1, 11):
        id = f"R{rid}D{did}"
        output_data.append([id, file_blocks[id]])

output_df = pd.DataFrame(output_data, columns=['id', 'file blocks'])

output_df.to_csv('filtered file blocks.csv', index=False)


print(output_df)

total_file_blocks = sum(file_blocks.values())
print("sum of all filtered file block :",total_file_blocks)

"""`*Convolutional Neural Network Model*`"""

import pandas as pd
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from keras.models import Sequential
from keras.layers import Conv2D, Flatten, Dense, Dropout

data_path = "/content/filtered data(60%).csv"
data = pd.read_csv(data_path)

le = LabelEncoder()
data[['rid', 'did', 'fid', 'bids']] = data[['rid', 'did', 'fid', 'bids']].apply(le.fit_transform)

X_categorical = data[['rid', 'did', 'fid', 'bids']].values
X_image = data['support_rank'].values
y = (data['support_rank'] > 0.5).astype(int)
X_train_cat, X_test_cat, X_train_img, X_test_img, y_train, y_test = train_test_split(X_categorical, X_image, y, test_size=0.2, random_state=42)

scaler = StandardScaler()
X_train_cat_scaled = scaler.fit_transform(X_train_cat)
X_test_cat_scaled = scaler.transform(X_test_cat)

X_train_img = X_train_img.reshape(X_train_img.shape[0], 1, 1, 1)
X_test_img = X_test_img.reshape(X_test_img.shape[0], 1, 1, 1)

model = Sequential([
    Conv2D(32, kernel_size=(1, 1), activation='relu', input_shape=(1, 1, 1)),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

model.fit(X_train_img, y_train, epochs=10, batch_size=32, verbose=1)

model.save('trained_model.h5')

import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder, StandardScaler
from keras.models import load_model
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import RandomOverSampler

model = load_model('/content/trained_model.h5')

original_data_path = "/content/filtered data(60%).csv"
original_data = pd.read_csv(original_data_path)

testing_file = pd.read_csv('/content/drive/MyDrive/requests1.csv')

le = LabelEncoder()
X_test = testing_file[['rid', 'did', 'fid', 'bids']].apply(le.fit_transform)

scaler = StandardScaler()
X_test = scaler.fit_transform(X_test)
X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1], 1)

y_pred = (model.predict(X_test_img) > 0.5).astype(int)

mask = testing_file[['rid', 'did', 'fid', 'bids']].apply(tuple, axis=1).isin(
    original_data[['rid', 'did', 'fid', 'bids']].apply(tuple, axis=1)
)
testing_file['Result'] = np.where(mask, 'HIT', 'MISS')

print(testing_file)

# # Evaluating the model
# y_pred = (model.predict([X_test_img, X_test_cat_scaled]) > 0.5).astype(int)
# print(classification_report(y_test, y_pred))

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

y_pred = (model.predict(X_test_img) > 0.5).astype(int)

acc = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
error_rate = 1 - acc


print(f"Accuracy: {acc:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1-score: {f1:.4f}")
print(f"Error Rate: {error_rate:.4f}")
print("Confusion Matrix:\n", conf_matrix)

testing_file.to_csv('HIT or MISS.csv', index=False)

print("Number of 'HIT' instances:", (testing_file['Result'] == 'HIT').sum())
print("Number of 'MISS' instances:", (testing_file['Result'] == 'MISS').sum())

import pandas as pd

testing_file = pd.read_csv('/content/HIT or MISS.csv')

hit_instances = (testing_file['Result'] == 'HIT').sum()
miss_instances = (testing_file['Result'] == 'MISS').sum()
total_instances = len(testing_file)

hit_ratio = hit_instances / total_instances
miss_ratio = miss_instances / total_instances

print(f"Number of 'HIT' instances: {hit_instances}")
print(f"Number of 'MISS' instances: {miss_instances}")
print(f"Total number of instances: {total_instances}")
print(f"Hit Ratio: {hit_ratio:.2%}")
print(f"Miss Ratio: {miss_ratio:.2%}")

import pandas as pd
import matplotlib.pyplot as plt

testing_file = pd.read_csv('HIT or MISS.csv')

hit_instances = (testing_file['Result'] == 'HIT').sum()
miss_instances = (testing_file['Result'] == 'MISS').sum()
total_instances = len(testing_file)

hit_ratio = hit_instances / total_instances
miss_ratio = miss_instances / total_instances

# Plotting
plt.figure(figsize=(8, 6))
plt.bar(['Hit', 'Miss'], [hit_ratio, miss_ratio], color=['green', 'red'])
plt.title('Hit and Miss Ratios')
plt.xlabel('Result')
plt.ylabel('Ratio')
plt.ylim(0, 1)
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix, classification_report

# Function to plot confusion matrix
def plot_confusion_matrix(y_test, y_pred, labels):
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(16, 6))
    plt.subplot(1, 3, 1)
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=labels, yticklabels=labels)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')

# Function to plot ROC curve
def plot_roc_curve(y_test, y_pred_prob):
    fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)
    roc_auc = roc_auc_score(y_test, y_pred_prob)

    plt.subplot(1, 3, 2)
    plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.2f})')
    plt.plot([0, 1], [0, 1], 'r--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc="lower right")

# Function to plot classification report
def plot_classification_report(y_test, y_pred):
    report = classification_report(y_test, y_pred, output_dict=True)
    plt.subplot(1, 3, 3)
    sns.heatmap(pd.DataFrame(report).iloc[:-1, :].T, annot=True, fmt=".2f", cmap="Blues")
    plt.title('Classification Report')

# Plot confusion matrix, ROC curve, and classification report for CNN model
plt.figure(figsize=(18, 6))
plot_confusion_matrix(y_test, y_pred, ['Not Support', 'Support'])
plot_roc_curve(y_test, y_pred)
plot_classification_report(y_test, y_pred)
plt.tight_layout()

plt.show()

import matplotlib.pyplot as plt

# Count the number of 'HIT' and 'MISS' instances
hit_count = (testing_file['Result'] == 'HIT').sum()
miss_count = (testing_file['Result'] == 'MISS').sum()

# Create a pie chart
labels = ['HIT', 'MISS']
sizes = [hit_count, miss_count]
colors = ['lightblue', 'lightcoral']
explode = (0.1, 0)  # explode 1st slice

plt.figure(figsize=(8, 6))
plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=140)
plt.title('Ratio of HIT and MISS')
plt.axis('equal')
plt.show()

"""`*Multilayer Perceptron Model*`



"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Dense, Dropout
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix


data_path = "/content/filtered data(60%).csv"
data = pd.read_csv(data_path)

le = LabelEncoder()
data[['rid', 'did', 'fid', 'bids']] = data[['rid', 'did', 'fid', 'bids']].apply(le.fit_transform)

X_categorical = data[['rid', 'did', 'fid', 'bids']].values
X_image = data['support_rank'].values.reshape(-1, 1)
y = (data['support_rank'] > 0.5).astype(int)

scaler = StandardScaler()
X_categorical_scaled = scaler.fit_transform(X_categorical)

X_train_cat, X_test_cat, X_train_img, X_test_img, y_train, y_test = train_test_split(
    X_categorical_scaled, X_image, y, test_size=0.2, random_state=42
)

X_train = np.concatenate((X_train_cat, X_train_img), axis=1)
X_test = np.concatenate((X_test_cat, X_test_img), axis=1)

model = Sequential([
    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1, validation_split=0.2)



test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)
print(f"Test Loss: {test_loss:.4f}")
print(f"Test Accuracy: {test_accuracy:.4f}")

y_pred = model.predict(X_test)
y_pred = (y_pred > 0.5).astype(int).flatten()

print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# Save the trained model to disk
model.save('/content/MLP_model.h5')
print("Model saved successfully!")

import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder, StandardScaler
from keras.models import load_model
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import RandomOverSampler

model = load_model('/content/MLP_model.h5')

original_data_path = "/content/filtered data(60%).csv"
original_data = pd.read_csv(original_data_path)

testing_file = pd.read_csv('/content/drive/MyDrive/requests1.csv')

le = LabelEncoder()
X_test = testing_file[['rid', 'did', 'fid', 'bids']].apply(le.fit_transform)

scaler = StandardScaler()
X_test = scaler.fit_transform(X_test)

X_test = X_test.reshape(X_test.shape[0], -1)

y = (data['support_rank'] > 0.5).astype(int)

mask = testing_file[['rid', 'did', 'fid', 'bids']].apply(tuple, axis=1).isin(
    original_data[['rid', 'did', 'fid', 'bids']].apply(tuple, axis=1)
)
testing_file['Result'] = np.where(mask, 'HIT', 'MISS')

print(testing_file)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix


acc = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
error_rate = 1 - acc


print(f"Accuracy: {acc:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1-score: {f1:.4f}")
print(f"Error Rate: {error_rate:.4f}")
print("Confusion Matrix:\n", conf_matrix)

testing_file.to_csv('HIT or MISS.csv', index=False)

print("Number of 'HIT' instances:", (testing_file['Result'] == 'HIT').sum())
print("Number of 'MISS' instances:", (testing_file['Result'] == 'MISS').sum())

import pandas as pd

testing_file = pd.read_csv('/content/HIT or MISS.csv')

hit_instances = (testing_file['Result'] == 'HIT').sum()
miss_instances = (testing_file['Result'] == 'MISS').sum()
total_instances = len(testing_file)

hit_ratio = hit_instances / total_instances
miss_ratio = miss_instances / total_instances

print(f"Number of 'HIT' instances: {hit_instances}")
print(f"Number of 'MISS' instances: {miss_instances}")
print(f"Total number of instances: {total_instances}")
print(f"Hit Ratio: {hit_ratio:.2%}")
print(f"Miss Ratio: {miss_ratio:.2%}")

import pandas as pd
import matplotlib.pyplot as plt

testing_file = pd.read_csv('HIT or MISS.csv')

hit_instances = (testing_file['Result'] == 'HIT').sum()
miss_instances = (testing_file['Result'] == 'MISS').sum()
total_instances = len(testing_file)

hit_ratio = hit_instances / total_instances
miss_ratio = miss_instances / total_instances

# Plotting
plt.figure(figsize=(8, 6))
plt.bar(['Hit', 'Miss'], [hit_ratio, miss_ratio], color=['green', 'red'])
plt.title('Hit and Miss Ratios')
plt.xlabel('Result')
plt.ylabel('Ratio')
plt.ylim(0, 1)
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix, classification_report

# Function to plot confusion matrix
def plot_confusion_matrix(y_test, y_pred, labels):
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(16, 6))
    plt.subplot(1, 3, 1)
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=labels, yticklabels=labels)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title('Confusion Matrix')

# Function to plot ROC curve
def plot_roc_curve(y_test, y_pred_prob):
    fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)
    roc_auc = roc_auc_score(y_test, y_pred_prob)

    plt.subplot(1, 3, 2)
    plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.2f})')
    plt.plot([0, 1], [0, 1], 'r--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc="lower right")

# Function to plot classification report
def plot_classification_report(y_test, y_pred):
    report = classification_report(y_test, y_pred, output_dict=True)
    plt.subplot(1, 3, 3)
    sns.heatmap(pd.DataFrame(report).iloc[:-1, :].T, annot=True, fmt=".2f", cmap="Blues")
    plt.title('Classification Report')

# Plot confusion matrix, ROC curve, and classification report for CNN model
plt.figure(figsize=(18, 6))
plot_confusion_matrix(y_test, y_pred, ['Not Support', 'Support'])
plot_roc_curve(y_test, y_pred)
plot_classification_report(y_test, y_pred)
plt.tight_layout()

plt.show()

import matplotlib.pyplot as plt

# Count the number of 'HIT' and 'MISS' instances
hit_count = (testing_file['Result'] == 'HIT').sum()
miss_count = (testing_file['Result'] == 'MISS').sum()

# Create a pie chart
labels = ['HIT', 'MISS']
sizes = [hit_count, miss_count]
colors = ['lightblue', 'lightcoral']
explode = (0.1, 0)  # explode 1st slice

plt.figure(figsize=(8, 6))
plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=140)
plt.title('Ratio of HIT and MISS')
plt.axis('equal')
plt.show()